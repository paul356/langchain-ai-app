# LangChain AI Application - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# Model Provider Selection
# Options: 'openai', 'ollama', 'qwen'
MODEL_PROVIDER=ollama

# Model Name (provider-specific)
# - For OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.
# - For Ollama: llama2, mistral, qwen3:latest, etc.
# - For Qwen: qwen-max, qwen-plus, qwen-turbo, qwen3-max, etc.
MODEL_NAME=qwen3:latest

# Model Temperature (0.0-1.0)
# Lower values = more deterministic, Higher values = more creative
MODEL_TEMPERATURE=0.7

# ============================================================================
# OPENAI CONFIGURATION (if MODEL_PROVIDER=openai)
# ============================================================================

# OpenAI API Key (required for OpenAI models)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Custom OpenAI API endpoint
# OPENAI_BASE_URL=https://api.openai.com/v1

# ============================================================================
# OLLAMA CONFIGURATION (if MODEL_PROVIDER=ollama)
# ============================================================================

# Ollama Server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Note: Make sure Ollama is running and the model is pulled:
# ollama pull qwen3:latest

# ============================================================================
# QWEN CONFIGURATION (if MODEL_PROVIDER=qwen)
# ============================================================================

# Qwen/Dashscope API Key (required for Qwen models)
# Get your key from: https://dashscope.console.aliyun.com/
QWEN_API_KEY=your_qwen_api_key_here

# Alternative environment variable name (same as QWEN_API_KEY)
# DASHSCOPE_API_KEY=your_dashscope_api_key_here

# Qwen API Base URL (default: Dashscope compatible endpoint)
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# ============================================================================
# EMBEDDING MODEL CONFIGURATION
# ============================================================================

# Embedding Provider Selection
# Options: 'openai', 'ollama', 'dashscope'
EMBEDDING_PROVIDER=ollama

# Embedding Model Name (provider-specific)
# - For OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# - For Ollama: nomic-embed-text, mxbai-embed-large, all-minilm
# - For Dashscope: text-embedding-v1, text-embedding-v2, text-embedding-v3, text-embedding-v4
EMBEDDING_MODEL=nomic-embed-text

# Dashscope API Key (required for Dashscope embeddings)
# Same as QWEN_API_KEY or DASHSCOPE_API_KEY above
# Get your key from: https://dashscope.console.aliyun.com/
# DASHSCOPE_API_KEY=your_dashscope_api_key_here

# ============================================================================
# QWEN MODEL OPTIONS
# ============================================================================

# Available Qwen models:
# - qwen-max: Latest and most capable model (recommended)
# - qwen-plus: Balanced performance and cost
# - qwen-turbo: Fast and cost-effective
# - qwen-long: Extended context window (10M tokens)
# - qwen3-max: Latest Qwen 3 series model
# - qwen2.5-72b-instruct: Qwen 2.5 large model
# - qwen2.5-32b-instruct: Qwen 2.5 medium model
# - qwen2.5-14b-instruct: Qwen 2.5 small model

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# Example 1: Using OpenAI GPT-4
# MODEL_PROVIDER=openai
# MODEL_NAME=gpt-4
# OPENAI_API_KEY=sk-...

# Example 2: Using Local Ollama with Qwen3
# MODEL_PROVIDER=ollama
# MODEL_NAME=qwen3:latest
# OLLAMA_BASE_URL=http://localhost:11434

# Example 3: Using Qwen Cloud API (qwen-max)
# MODEL_PROVIDER=qwen
# MODEL_NAME=qwen-max
# QWEN_API_KEY=sk-...

# Example 4: Using Qwen3-max (latest)
# MODEL_PROVIDER=qwen
# MODEL_NAME=qwen3-max
# QWEN_API_KEY=sk-...
