{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6de198c",
   "metadata": {},
   "source": [
    "# ü§ñ Building AI Applications with LangChain: Complete Tutorial\n",
    "\n",
    "Welcome to this comprehensive tutorial on building AI applications using LangChain! This notebook will guide you through creating increasingly complex AI applications, from basic chatbots to sophisticated agents.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Environment Setup** - Installing and configuring LangChain\n",
    "2. **Basic LLM Integration** - Working with OpenAI and local models\n",
    "3. **Prompt Engineering** - Advanced prompting techniques\n",
    "4. **Memory Systems** - Maintaining conversation context\n",
    "5. **Document Processing** - Loading and processing documents\n",
    "6. **Vector Stores** - Embedding and similarity search\n",
    "7. **RAG Systems** - Retrieval-Augmented Generation\n",
    "8. **Custom Tools** - Building specialized functionality\n",
    "9. **Agents** - Autonomous reasoning and action\n",
    "10. **Production Features** - Streaming, monitoring, and deployment\n",
    "\n",
    "Let's start building! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65fc45",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Installation\n",
    "\n",
    "First, let's set up our environment and install the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1067b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ LangChain Tutorial Environment\n",
      "‚úÖ Libraries imported successfully!\n",
      "üêç Python version: 3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]\n",
      "‚ö†Ô∏è  OpenAI API key not found. You can still use local models!\n",
      "\n",
      "Ready to start building AI applications! üöÄ\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "# !pip install langchain langchain-openai langchain-community python-dotenv faiss-cpu\n",
    "\n",
    "# Import essential libraries\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üì¶ LangChain Tutorial Environment\")\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "\n",
    "# Check if API key is available\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_key:\n",
    "    print(\"üîë OpenAI API key found!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OpenAI API key not found. You can still use local models!\")\n",
    "    \n",
    "print(\"\\nReady to start building AI applications! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed68e35",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Integration\n",
    "\n",
    "Let's start with the basics - connecting to a Large Language Model and making simple API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b628d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up LLM connection...\n",
      "ü¶ô Using Ollama model: qwen3:latest at http://192.168.71.5:11434\n",
      "üß™ Testing connection with a simple question...\n",
      "\n",
      "ü§ñ AI Response:\n",
      "<think>\n",
      "Okay, the user asked for a joke about programming. Let me think of a good one. I need to make sure it's appropriate and not too technical. Maybe something with common programming terms.\n",
      "\n",
      "Hmm, there's the classic \"Why do programmers prefer dark mode?\" joke. Wait, that's been done before. Maybe something with debugging? Like the \"debugger\" pun. Or maybe a play on words with code terms.\n",
      "\n",
      "Wait, here's an idea: \"Why do programmers always mix up Halloween and Christmas? Because Oct 31 equals Dec 25!\" Oh, that's a classic. But maybe the user has heard that one. Let me think of another.\n",
      "\n",
      "What about the one with the programmer in a bar? \"Why do programmers prefer dark mode? Because light mode is too bright and they can't see the errors!\" No, that's similar to the first one. Maybe something with coffee and debugging?\n",
      "\n",
      "Wait, here's another: \"Why did the programmer quit his job? Because he didn't get arrays!\" That's a play on \"raises\" and \"arrays\". That's a good one. Or maybe the one about the binary joke: \"There are 10 types of people in the world: those who understand binary and those who don't.\"\n",
      "\n",
      "Wait, the user might have heard that too. Let me check if there's a less common one. Maybe something about code comments? Like, \"Why do programmers hate nature? Because it has too many bugs.\" Wait, that's not very funny. \n",
      "\n",
      "Alternatively, \"Why do programmers prefer to work at home? Because the office has too many bugs.\" Hmm. Maybe the one about the programmer's favorite part of the computer? \"The keyboard, because it's the only part they can type on.\" Not sure.\n",
      "\n",
      "Wait, maybe go with the \"Oct 31 equals Dec 25\" joke. It's a classic but still a good pun. Let me confirm the math: Octal 31 is 3*8 +1=25, which is decimal 25. So that's correct. Yeah, that's a solid joke. Let me present that.\n",
      "</think>\n",
      "\n",
      "Sure! Here's a classic programming joke:  \n",
      "\n",
      "**\"Why do programmers always mix up Halloween and Christmas?**  \n",
      "Because *Oct 31* equals *Dec 25*!\"  \n",
      "\n",
      "*(Hint: Octal 31 is 25 in decimal.)* üéÉüéÑ\n"
     ]
    }
   ],
   "source": [
    "# Basic LLM setup - configured for your Ollama server\n",
    "from langchain_ollama import OllamaLLM\n",
    "# Commented out OpenAI import since we're using Ollama\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "def setup_llm(use_openai=False, model_name=None):\n",
    "    \"\"\"Setup LLM - configured to use your Ollama server by default.\"\"\"\n",
    "    # Your Ollama server configuration\n",
    "    ollama_url = os.getenv(\"OLLAMA_BASE_URL\", \"http://192.168.71.5:11434\")\n",
    "    \n",
    "    if use_openai and os.getenv(\"OPENAI_API_KEY\"):\n",
    "        # Using OpenAI (only if specifically requested and API key exists)\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        model = model_name or \"gpt-3.5-turbo\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        print(f\"ü§ñ Using OpenAI model: {model}\")\n",
    "        return llm\n",
    "    else:\n",
    "        # Using your local Ollama server (default)\n",
    "        model = model_name or os.getenv(\"MODEL_NAME\", \"qwen3:latest\")\n",
    "        llm = OllamaLLM(\n",
    "            model=model,\n",
    "            base_url=ollama_url\n",
    "        )\n",
    "        print(f\"ü¶ô Using Ollama model: {model} at {ollama_url}\")\n",
    "        return llm\n",
    "\n",
    "# Initialize LLM - using your Ollama server\n",
    "try:\n",
    "    print(\"üîß Setting up LLM connection...\")\n",
    "    llm = setup_llm(use_openai=False)  # Explicitly using Ollama\n",
    "    \n",
    "    # Test basic interaction with your server\n",
    "    print(\"üß™ Testing connection with a simple question...\")\n",
    "    response = llm.invoke(\"Hello! Tell me a joke about programming.\")\n",
    "    print(f\"\\nü§ñ AI Response:\\n{response}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error setting up LLM: {e}\")\n",
    "    print(\"üí° Please check:\")\n",
    "    print(\"  1. Your Ollama server is running at http://192.168.71.5:11434\")\n",
    "    print(\"  2. The qwen3:latest model is available\")\n",
    "    print(\"  3. Your .env file has the correct OLLAMA_BASE_URL setting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ac097",
   "metadata": {},
   "source": [
    "## 3. Prompt Templates and Chain Basics\n",
    "\n",
    "Prompt templates allow us to create reusable, dynamic prompts. Chains help us connect different components together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664ba66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Simple Prompt Template:\n",
      "Explain machine learning in simple terms that a beginner could understand.\n",
      "\n",
      "üí¨ Chat Prompt Template:\n",
      "system: You are a helpful AI tutor specializing in Python programming.\n",
      "human: Please explain list comprehensions with examples.\n",
      "\n",
      "üîó Chain Result:\n",
      "<think>\n",
      "Okay, the user is asking about the difference between supervised and unsupervised learning. Let me start by recalling the basics. Supervised learning uses labeled data, right? So the model learns from examples where the input and output are known. Examples include classification and regression tasks. Like predicting house prices based on features, which is regression. Or classifying emails as spam or not, which is classification.\n",
      "\n",
      "Now, unsupervised learning doesn't have labels. The model tries to find patterns or structures in the data on its own. Clustering and dimensionality reduction are common here. For example, customer segmentation using clustering algorithms like K-means. Or maybe something like recommendation systems, but wait, recommendations can sometimes be semi-supervised. Maybe I should stick to pure examples.\n",
      "\n",
      "Wait, the user might be a student or someone starting in data science. They might need clear, simple examples. I should make sure to contrast the two methods clearly. Also, maybe mention the types of problems each is suited for. Supervised is for prediction, unsupervised for exploration. Are there any common misconceptions? Like, sometimes people think unsupervised is just clustering, but there's also association rule mining and anomaly detection.\n",
      "\n",
      "I should also mention the use cases. For instance, supervised is used in applications like fraud detection (classification) or predicting stock prices (regression). Unsupervised is used in market basket analysis (association) or image compression (dimensionality reduction). Maybe include a table to summarize the differences, but the user didn't ask for that, so maybe just a clear explanation.\n",
      "\n",
      "Wait, the user asked for examples. So I need to make sure each type has a couple of examples. Also, maybe mention that supervised requires labeled data, which can be expensive to obtain, while unsupervised works with unlabeled data, which is more common but harder to evaluate. Oh, and evaluation metrics differ too. Supervised uses accuracy, precision, recall, etc., while unsupervised might use metrics like silhouette score or domain-specific measures.\n",
      "\n",
      "I should check if I'm mixing up any concepts. For example, reinforcement learning is a third type, but the user didn't ask about that. Focus on the two. Also, maybe clarify that unsupervised learning is more about discovering hidden patterns rather than making predictions. That's a key difference. Alright, I think I have the structure. Start with definitions, then types, examples, and maybe a summary to highlight the main differences.\n",
      "</think>\n",
      "\n",
      "Certainly! Here's a clear explanation of **supervised learning** vs. **unsupervised learning**, along with examples to illustrate the differences:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Supervised Learning**  \n",
      "**Definition**:  \n",
      "Supervised learning involves training a model using **labeled data** (input-output pairs). The model learns to map inputs to outputs by finding patterns in the data. It is \"supervised\" because the algorithm is guided by the correct answers (labels) during training.  \n",
      "\n",
      "**Types of Tasks**:  \n",
      "- **Classification**: Predicting discrete labels (e.g., spam vs. not spam).  \n",
      "- **Regression**: Predicting continuous values (e.g., house prices).  \n",
      "\n",
      "**Examples**:  \n",
      "- **Email Spam Detection**:  \n",
      "  - Input: Email content (text, sender, keywords).  \n",
      "  - Output: Label (spam/ham).  \n",
      "  - The model learns to classify emails based on historical spam/ham data.  \n",
      "\n",
      "- **House Price Prediction**:  \n",
      "  - Input: Features like square footage, location, number of bedrooms.  \n",
      "  - Output: Predicted price (a continuous value).  \n",
      "  - The model learns the relationship between features and prices.  \n",
      "\n",
      "- **Medical Diagnosis**:  \n",
      "  - Input: Patient symptoms, lab results.  \n",
      "  - Output: Diagnosis (e.g., cancer vs. benign tumor).  \n",
      "\n",
      "**Key Characteristics**:  \n",
      "- Requires labeled data.  \n",
      "- Evaluated using metrics like accuracy, precision, recall, or mean squared error.  \n",
      "- Used for **prediction** and **classification** tasks.  \n",
      "\n",
      "---\n",
      "\n",
      "### **2. Unsupervised Learning**  \n",
      "**Definition**:  \n",
      "Unsupervised learning uses **unlabeled data** (no predefined outputs). The model identifies hidden patterns, structures, or relationships in the data without explicit guidance.  \n",
      "\n",
      "**Types of Tasks**:  \n",
      "- **Clustering**: Grouping similar data points (e.g., customer segments).  \n",
      "- **Dimensionality Reduction**: Simplifying data by reducing features (e.g., compressing images).  \n",
      "- **Association**: Discovering relationships between variables (e.g., \"customers who buy X also buy Y\").  \n",
      "\n",
      "**Examples**:  \n",
      "- **Customer Segmentation**:  \n",
      "  - Input: Customer purchase history, demographics.  \n",
      "  - Output: Grouping customers into segments (e.g., \"frequent buyers,\" \"discount seekers\").  \n",
      "  - The model finds clusters of similar customers without prior labels.  \n",
      "\n",
      "- **Anomaly Detection**:  \n",
      "  - Input: Network traffic data.  \n",
      "  - Output: Identifying unusual patterns (e.g., potential security breaches).  \n",
      "  - The model learns \"normal\" behavior and flags deviations.  \n",
      "\n",
      "- **Recommendation Systems**:  \n",
      "  - Input: User-item interactions (e.g., \"user X rated movie Y highly\").  \n",
      "  - Output: Suggesting items based on similarities (e.g., \"users like you also liked Z\").  \n",
      "  - The model identifies associations between items and users.  \n",
      "\n",
      "**Key Characteristics**:  \n",
      "- Uses unlabeled data.  \n",
      "- Evaluated using metrics like silhouette score, reconstruction error, or domain expertise.  \n",
      "- Used for **exploration**, **pattern discovery**, and **data compression**.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Summary: Key Differences**  \n",
      "| **Aspect**               | **Supervised Learning**          | **Unsupervised Learning**         |  \n",
      "|--------------------------|----------------------------------|-----------------------------------|  \n",
      "| **Data Type**            | Labeled (input-output pairs)     | Unlabeled (no predefined outputs) |  \n",
      "| **Goal**                 | Predict outputs (classification/regression) | Discover patterns/structures |  \n",
      "| **Common Tasks**         | Classification, Regression       | Clustering, Dimensionality Reduction, Association |  \n",
      "| **Evaluation Metrics**   | Accuracy, Precision, MSE         | Silhouette Score, Reconstruction Error |  \n",
      "| **Use Cases**            | Prediction, Diagnosis            | Exploration, Anomaly Detection    |  \n",
      "\n",
      "---\n",
      "\n",
      "### **When to Use Which?**  \n",
      "- Use **supervised learning** when you have labeled data and want to make predictions (e.g., forecasting sales, classifying images).  \n",
      "- Use **unsupervised learning** when you want to explore data, find hidden patterns, or reduce complexity (e.g., market basket analysis, customer segmentation).  \n",
      "\n",
      "Let me know if you'd like to dive deeper into specific algorithms (e.g., SVM for classification, K-means for clustering)! üòä\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 1. Simple Prompt Template\n",
    "simple_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms that a beginner could understand.\"\n",
    ")\n",
    "\n",
    "print(\"üéØ Simple Prompt Template:\")\n",
    "print(simple_prompt.format(topic=\"machine learning\"))\n",
    "\n",
    "# 2. Chat Prompt Template (for chat models)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI tutor specializing in {subject}.\"),\n",
    "    (\"human\", \"Please explain {topic} with examples.\")\n",
    "])\n",
    "\n",
    "print(\"\\nüí¨ Chat Prompt Template:\")\n",
    "formatted_prompt = chat_prompt.format_messages(\n",
    "    subject=\"Python programming\", \n",
    "    topic=\"list comprehensions\"\n",
    ")\n",
    "for message in formatted_prompt:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "# 3. Creating a Basic Chain\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test the chain\n",
    "try:\n",
    "    result = chain.invoke({\n",
    "        \"subject\": \"data science\",\n",
    "        \"topic\": \"the difference between supervised and unsupervised learning\"\n",
    "    })\n",
    "    print(f\"\\nüîó Chain Result:\\n{result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running chain: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715caa1",
   "metadata": {},
   "source": [
    "## 4. Memory Implementation\n",
    "\n",
    "Memory allows our AI to remember previous conversations and maintain context across multiple interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3924149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Creating Memory-Enabled Chatbot with your Ollama server...\n",
      "üß† Testing Memory-Enabled Chatbot:\n",
      "----------------------------------------\n",
      "User: Hi, my name is Alice and I'm learning Python.\n",
      "Bot: <think>\n",
      "Okay, the user introduced herself as Alice and mentioned she's learning Python. I need to respond in a friendly and helpful manner. Let me start by welcoming her and expressing enthusiasm that she's learning Python. Maybe ask how she's finding the learning process so far. It's important to offer assistance with any specific questions or topics she might be working on. I should keep the tone positive and encouraging. Let me make sure the response is concise but welcoming, and invite her to ask for help if needed. Avoid any technical jargon since she's just starting out. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "Hello, Alice! Welcome to the world of Python programming. I'm glad to hear you're learning Python‚Äîit's a fantastic language for beginners! How are you finding the learning process so far? If you have any questions, need help with a specific topic, or want to work through a problem, feel free to ask. I'm here to help! üêç‚ú®\n",
      "\n",
      "User: What programming concepts should I focus on first?\n",
      "Bot: <think>\n",
      "Okay, Alice is learning Python and asked about the first programming concepts to focus on. Let me think. She's a beginner, so I should start with the basics. First, understanding variables and data types is essential. Then control structures like loops and conditionals. Functions are important too. Maybe mention data structures like lists and dictionaries. Oh, and error handling with try-except. Also, maybe touch on modules and packages. But I shouldn't overwhelm her. Let me structure this step by step, making sure to explain each concept briefly and encourage practice. Maybe end with an offer to help with specific topics. Need to keep it friendly and supportive.\n",
      "</think>\n",
      "\n",
      "Great question! When starting with Python, focus on these foundational concepts first:\n",
      "\n",
      "1. **Variables & Data Types**  \n",
      "   - Store values (e.g., `x = 5`, `name = \"Alice\"`)  \n",
      "   - Learn types like integers, strings, booleans, and floats.\n",
      "\n",
      "2. **Control Flow**  \n",
      "   - Use `if/elif/else` for decision-making.  \n",
      "   - Master `for` and `while` loops for repetition.\n",
      "\n",
      "3. **Functions**  \n",
      "   - Define reusable blocks with `def function_name():`.  \n",
      "   - Practice parameters, return values, and scope.\n",
      "\n",
      "4. **Data Structures**  \n",
      "   - **Lists** (`[1, 2, 3]`) for ordered collections.  \n",
      "   - **Dictionaries** (`{\"name\": \"Alice\"}`) for key-value pairs.  \n",
      "   - **Tuples** and **sets** as bonus topics later.\n",
      "\n",
      "5. **Error Handling**  \n",
      "   - Use `try/except` to catch and debug runtime errors.\n",
      "\n",
      "6. **Modules & Packages**  \n",
      "   - Import libraries like `math` or `random` to extend Python's capabilities.\n",
      "\n",
      "**Pro Tip**: Practice writing small programs (e.g., a calculator, to-do list) to solidify these concepts. Let me know if you'd like examples or help with a specific topic! üòä\n",
      "\n",
      "User: What was my name again?\n",
      "Bot: <think>\n",
      "Okay, the user asked, \"What was my name again?\" Let me check the conversation history.\n",
      "\n",
      "Looking back, the first message from the human was: \"Hi, my name is Alice and I'm learning Python.\" So their name is Alice. The AI responded welcomingly. Then the user asked about programming concepts, and the AI provided a detailed answer. Now, the user is asking for their name again. \n",
      "\n",
      "Wait, maybe they forgot or are testing if I remember. Since the system instructions say to use conversation history for context-aware responses, I should recall that their name was mentioned in the first message. The AI should respond with \"Alice\" as their name. No need to repeat the entire history, just the name. Keep it friendly and confirm their name while offering further help. Make sure the response is concise and matches the previous tone.\n",
      "</think>\n",
      "\n",
      "Your name is Alice! üòä Glad to see you're back. How can I assist you today?\n",
      "\n",
      "üìù Current Memory Buffer:\n",
      "Human: Hi, my name is Alice and I'm learning Python.\n",
      "AI: <think>\n",
      "Okay, the user introduced herself as Alice and mentioned she's learning Python. I need to respond in a friendly and helpful manner. Let me start by welcoming her and expressing enthusiasm that she's learning Python. Maybe ask how she's finding the learning process so far. It's important to offer assistance with any specific questions or topics she might be working on. I should keep the tone positive and encouraging. Let me make sure the response is concise but welcoming, and invite her to ask for help if needed. Avoid any technical jargon since she's just starting out. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "Hello, Alice! Welcome to the world of Python programming. I'm glad to hear you're learning Python‚Äîit's a fantastic language for beginners! How are you finding the learning process so far? If you have any questions, need help with a specific topic, or want to work through a problem, feel free to ask. I'm here to help! üêç‚ú®\n",
      "Human: What programming concepts should I focus on first?\n",
      "AI: <think>\n",
      "Okay, Alice is learning Python and asked about the first programming concepts to focus on. Let me think. She's a beginner, so I should start with the basics. First, understanding variables and data types is essential. Then control structures like loops and conditionals. Functions are important too. Maybe mention data structures like lists and dictionaries. Oh, and error handling with try-except. Also, maybe touch on modules and packages. But I shouldn't overwhelm her. Let me structure this step by step, making sure to explain each concept briefly and encourage practice. Maybe end with an offer to help with specific topics. Need to keep it friendly and supportive.\n",
      "</think>\n",
      "\n",
      "Great question! When starting with Python, focus on these foundational concepts first:\n",
      "\n",
      "1. **Variables & Data Types**  \n",
      "   - Store values (e.g., `x = 5`, `name = \"Alice\"`)  \n",
      "   - Learn types like integers, strings, booleans, and floats.\n",
      "\n",
      "2. **Control Flow**  \n",
      "   - Use `if/elif/else` for decision-making.  \n",
      "   - Master `for` and `while` loops for repetition.\n",
      "\n",
      "3. **Functions**  \n",
      "   - Define reusable blocks with `def function_name():`.  \n",
      "   - Practice parameters, return values, and scope.\n",
      "\n",
      "4. **Data Structures**  \n",
      "   - **Lists** (`[1, 2, 3]`) for ordered collections.  \n",
      "   - **Dictionaries** (`{\"name\": \"Alice\"}`) for key-value pairs.  \n",
      "   - **Tuples** and **sets** as bonus topics later.\n",
      "\n",
      "5. **Error Handling**  \n",
      "   - Use `try/except` to catch and debug runtime errors.\n",
      "\n",
      "6. **Modules & Packages**  \n",
      "   - Import libraries like `math` or `random` to extend Python's capabilities.\n",
      "\n",
      "**Pro Tip**: Practice writing small programs (e.g., a calculator, to-do list) to solidify these concepts. Let me know if you'd like examples or help with a specific topic! üòä\n",
      "Human: What was my name again?\n",
      "AI: <think>\n",
      "Okay, the user asked, \"What was my name again?\" Let me check the conversation history.\n",
      "\n",
      "Looking back, the first message from the human was: \"Hi, my name is Alice and I'm learning Python.\" So their name is Alice. The AI responded welcomingly. Then the user asked about programming concepts, and the AI provided a detailed answer. Now, the user is asking for their name again. \n",
      "\n",
      "Wait, maybe they forgot or are testing if I remember. Since the system instructions say to use conversation history for context-aware responses, I should recall that their name was mentioned in the first message. The AI should respond with \"Alice\" as their name. No need to repeat the entire history, just the name. Keep it friendly and confirm their name while offering further help. Make sure the response is concise and matches the previous tone.\n",
      "</think>\n",
      "\n",
      "Your name is Alice! üòä Glad to see you're back. How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modern memory implementation using LangChain 1.0+\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class MemoryBot:\n",
    "    \"\"\"A chatbot with conversation memory using your Ollama server - Modern LangChain 1.0+ approach.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.chat_history = []  # Simple list to store conversation history\n",
    "        \n",
    "        # Create prompt with memory placeholder\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful assistant. Use the conversation history to provide context-aware responses.\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # Create the chain\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def chat(self, message):\n",
    "        \"\"\"Send a message and get a response with memory.\"\"\"\n",
    "        # Invoke the chain with current history\n",
    "        response = self.chain.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": self.chat_history\n",
    "        })\n",
    "        \n",
    "        # Add the new conversation to history\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=message),\n",
    "            AIMessage(content=response)\n",
    "        ])\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_memory(self):\n",
    "        \"\"\"Get current memory contents.\"\"\"\n",
    "        memory_str = \"\"\n",
    "        for msg in self.chat_history:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                memory_str += f\"Human: {msg.content}\\n\"\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                memory_str += f\"AI: {msg.content}\\n\"\n",
    "        return memory_str\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.chat_history = []\n",
    "\n",
    "# Create memory-enabled chatbot using your Ollama server\n",
    "print(\"üß† Creating Memory-Enabled Chatbot with your Ollama server...\")\n",
    "memory_bot = MemoryBot(llm)\n",
    "\n",
    "# Test conversation with memory\n",
    "print(\"üß† Testing Memory-Enabled Chatbot:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    # First message\n",
    "    response1 = memory_bot.chat(\"Hi, my name is Alice and I'm learning Python.\")\n",
    "    print(f\"User: Hi, my name is Alice and I'm learning Python.\")\n",
    "    print(f\"Bot: {response1}\\n\")\n",
    "\n",
    "    # Second message - bot should remember the name\n",
    "    response2 = memory_bot.chat(\"What programming concepts should I focus on first?\")\n",
    "    print(f\"User: What programming concepts should I focus on first?\")\n",
    "    print(f\"Bot: {response2}\\n\")\n",
    "\n",
    "    # Third message - testing memory retention\n",
    "    response3 = memory_bot.chat(\"What was my name again?\")\n",
    "    print(f\"User: What was my name again?\")\n",
    "    print(f\"Bot: {response3}\\n\")\n",
    "\n",
    "    print(\"üìù Current Memory Buffer:\")\n",
    "    print(memory_bot.get_memory())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in memory chat: {e}\")\n",
    "    print(\"üí° Make sure your Ollama server is running and accessible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c36912-45fd-4609-8a12-76f95fb287dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
